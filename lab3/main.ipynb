{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e7a518ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, ClusteringEvaluator\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.sql.functions import when, col, mean\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f3d228",
   "metadata": {},
   "source": [
    "### 1 Ирисы Фишера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21789624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- SepalLengthCm: double (nullable = true)\n",
      " |-- SepalWidthCm: double (nullable = true)\n",
      " |-- PetalLengthCm: double (nullable = true)\n",
      " |-- PetalWidthCm: double (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/opt/data/iris/iris.csv\", header=True, inferSchema=True)\n",
    "df.show(5)\n",
    "print(\"Schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16b3ae16-0334-4c48-b19b-87f29d888e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after StringIndexer:\n",
      "+---------------+-----+\n",
      "|        Species|label|\n",
      "+---------------+-----+\n",
      "|    Iris-setosa|  0.0|\n",
      "| Iris-virginica|  2.0|\n",
      "|Iris-versicolor|  1.0|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"Species\", outputCol=\"label\")\n",
    "df_indexed = indexer.fit(df).transform(df)\n",
    "\n",
    "print(\"Data after StringIndexer:\")\n",
    "df_indexed.select(\"Species\", \"label\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bfb0b28-cd77-4335-95c1-333f21266bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 104, Test count: 46\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "data = assembler.transform(df_indexed)\n",
    "\n",
    "# Разделение данных\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
    "print(f\"Train count: {train_data.count()}, Test count: {test_data.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f848131d-d1c6-48ef-afc2-2be3d7cd8cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.9348, F1: 0.9335\n",
      "+-----------+-----+----------+\n",
      "|    Species|label|prediction|\n",
      "+-----------+-----+----------+\n",
      "|Iris-setosa|  0.0|       0.0|\n",
      "|Iris-setosa|  0.0|       0.0|\n",
      "|Iris-setosa|  0.0|       0.0|\n",
      "|Iris-setosa|  0.0|       0.0|\n",
      "|Iris-setosa|  0.0|       0.0|\n",
      "|Iris-setosa|  0.0|       0.0|\n",
      "|Iris-setosa|  0.0|       0.0|\n",
      "|Iris-setosa|  0.0|       0.0|\n",
      "|Iris-setosa|  0.0|       0.0|\n",
      "|Iris-setosa|  0.0|       0.0|\n",
      "+-----------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "lr_model = lr.fit(train_data)\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "print(f\"Logistic Regression - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "predictions.select(\"Species\", \"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3abd5def-1fbb-4ef4-a5be-063d7cf7bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy: 0.9348, F1: 0.9335\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "dt_model = dt.fit(train_data)\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "\n",
    "dt_accuracy = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "dt_f1 = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"f1\"})\n",
    "print(f\"Decision Tree - Accuracy: {dt_accuracy:.4f}, F1: {dt_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e1af999-76bc-4954-8e2d-99a071caf751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means Silhouette score: 0.7342\n"
     ]
    }
   ],
   "source": [
    "kmeans_data = assembler.transform(df)\n",
    "\n",
    "kmeans = KMeans(featuresCol=\"features\", k=3, seed=42)\n",
    "kmeans_model = kmeans.fit(kmeans_data)\n",
    "kmeans_results = kmeans_model.transform(kmeans_data)\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(kmeans_results)\n",
    "print(f\"K-means Silhouette score: {silhouette:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b06aca",
   "metadata": {},
   "source": [
    "#### 2 Public bike use data 2014-2024 (MiBici)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d496edcc-4c2b-4a26-9eef-816c0001047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------+----------------+----------+-----------+----------+\n",
      "| id|                name|   obcn|        location|  latitude|  longitude|    status|\n",
      "+---+--------------------+-------+----------------+----------+-----------+----------+\n",
      "|  2|(GDL-001) C. Epig...|GDL-001|POLÍGONO CENTRAL| 20.666378| -103.34882|IN_SERVICE|\n",
      "|  3|(GDL-002) C. Colo...|GDL-002|POLÍGONO CENTRAL| 20.667228|   -103.366|IN_SERVICE|\n",
      "|  4|(GDL-003) C. Vidr...|GDL-003|POLÍGONO CENTRAL|  20.66769|-103.368252|IN_SERVICE|\n",
      "|  5|(GDL-004) C. Ghil...|GDL-004|POLÍGONO CENTRAL|  20.69175| -103.36255|IN_SERVICE|\n",
      "|  6|(GDL-005) C. San ...|GDL-005|POLÍGONO CENTRAL|20.6811575|-103.339363|IN_SERVICE|\n",
      "+---+--------------------+-------+----------------+----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- obcn: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/opt/data/bike\", header=True, inferSchema=True)\n",
    "df.show(5)\n",
    "print(\"Schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5fedb3c-cb03-4be9-af16-34d34e831d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущенные значения:\n",
      "id: 0\n",
      "name: 0\n",
      "obcn: 0\n",
      "location: 0\n",
      "latitude: 0\n",
      "longitude: 0\n",
      "status: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Пропущенные значения:\")\n",
    "for column in df.columns:\n",
    "    null_count = df.filter(col(column).isNull()).count()\n",
    "    print(f\"{column}: {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "887e6a2b-a439-4396-909b-ff1b009ea3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Географическая кластеризация станций:\n",
      "Silhouette Score: 0.6428\n",
      "\n",
      "Характеристики географических кластеров:\n",
      "+----------+------------------+-------------------+-------------+\n",
      "|prediction|      avg_latitude|      avg_longitude|station_count|\n",
      "+----------+------------------+-------------------+-------------+\n",
      "|         0| 20.66331470894737|-103.40242464210525|           57|\n",
      "|         1|20.678589033043483|-103.36811395478264|          115|\n",
      "|         2|20.649100779999998|-103.31597733809522|           42|\n",
      "|         3|20.726770622857153|-103.38809392380952|           42|\n",
      "|         4|  20.6826440437931|-103.34422569310341|          116|\n",
      "+----------+------------------+-------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"latitude\", \"longitude\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "cluster_data = assembler.transform(df)\n",
    "\n",
    "kmeans = KMeans(featuresCol=\"features\", k=5, seed=42)\n",
    "kmeans_model = kmeans.fit(cluster_data)\n",
    "kmeans_results = kmeans_model.transform(cluster_data)\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(kmeans_results)\n",
    "\n",
    "print(\"Географическая кластеризация станций:\")\n",
    "print(f\"Silhouette Score: {silhouette:.4f}\")\n",
    "\n",
    "# Анализ кластеров\n",
    "print(\"\\nХарактеристики географических кластеров:\")\n",
    "kmeans_results.groupBy(\"prediction\").agg(\n",
    "    mean(\"latitude\").alias(\"avg_latitude\"),\n",
    "    mean(\"longitude\").alias(\"avg_longitude\"),\n",
    "    count(\"*\").alias(\"station_count\")\n",
    ").orderBy(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8674abea-edea-4c96-9a2a-e6f9e0f5a269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классификация статуса станции:\n",
      "Accuracy: 0.9462\n",
      "F1 Score: 0.9201\n"
     ]
    }
   ],
   "source": [
    "indexer_status = StringIndexer(inputCol=\"status\", outputCol=\"label\")\n",
    "indexer_location = StringIndexer(inputCol=\"location\", outputCol=\"location_index\")\n",
    "\n",
    "assembler_class = VectorAssembler(\n",
    "    inputCols=[\"latitude\", \"longitude\", \"location_index\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", \n",
    "                           numTrees=50, seed=42)\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer_status, indexer_location, assembler_class, rf])\n",
    "\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "model = pipeline.fit(train_data)\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", \n",
    "                                             predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(\"Классификация статуса станции:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17a886a9-c11b-4aa6-969a-2e7228c408d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM кластеризация для анализа плотности:\n",
      "Log-Likelihood: -705.7909\n",
      "\n",
      "Плотность станций по кластерам:\n",
      "+----------+-------------+------------------------+------------------+-------------------+\n",
      "|prediction|station_count|avg_distance_from_center|      avg_latitude|      avg_longitude|\n",
      "+----------+-------------+------------------------+------------------+-------------------+\n",
      "|         0|          144|    0.022689990010803622|20.685812681250002|-103.35147230763887|\n",
      "|         1|           95|     0.05068054741645819|20.685846795789477|-103.34959180105265|\n",
      "|         2|          133|     0.03525897213494478| 20.66847754518796|-103.38307706315791|\n",
      "+----------+-------------+------------------------+------------------+-------------------+\n",
      "\n",
      "Распределение локаций по кластерам GMM:\n",
      "+----------+-----------------+-----+\n",
      "|prediction|         location|count|\n",
      "+----------+-----------------+-----+\n",
      "|         0| POLÍGONO CENTRAL|  137|\n",
      "|         0|TLQ-CORREDORATLAS|    4|\n",
      "|         0|   ZAPOPAN CENTRO|    3|\n",
      "|         1|TLQ-CORREDORATLAS|   45|\n",
      "|         1|   ZAPOPAN CENTRO|   41|\n",
      "|         1| POLÍGONO CENTRAL|    9|\n",
      "|         2| POLÍGONO CENTRAL|  133|\n",
      "+----------+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_distance = df.withColumn(\n",
    "    \"distance_from_center\",\n",
    "    sqrt(pow(col(\"latitude\") - lit(20.666378), 2) + \n",
    "         pow(col(\"longitude\") - lit(-103.34882), 2))\n",
    ")\n",
    "\n",
    "assembler_gmm = VectorAssembler(\n",
    "    inputCols=[\"latitude\", \"longitude\", \"distance_from_center\"],\n",
    "    outputCol=\"raw_features\"\n",
    ")\n",
    "df_gmm = assembler_gmm.transform(df_with_distance)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"raw_features\", outputCol=\"features\", \n",
    "                       withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(df_gmm)\n",
    "df_scaled = scaler_model.transform(df_gmm)\n",
    "\n",
    "gmm = GaussianMixture(featuresCol=\"features\", k=3, seed=42)\n",
    "gmm_model = gmm.fit(df_scaled)\n",
    "gmm_results = gmm_model.transform(df_scaled)\n",
    "\n",
    "gmm_summary = gmm_model.summary\n",
    "print(\"GMM кластеризация для анализа плотности:\")\n",
    "print(f\"Log-Likelihood: {gmm_summary.logLikelihood:.4f}\")\n",
    "\n",
    "print(\"\\nПлотность станций по кластерам:\")\n",
    "gmm_results.groupBy(\"prediction\").agg(\n",
    "    count(\"*\").alias(\"station_count\"),\n",
    "    mean(\"distance_from_center\").alias(\"avg_distance_from_center\"),\n",
    "    mean(\"latitude\").alias(\"avg_latitude\"),\n",
    "    mean(\"longitude\").alias(\"avg_longitude\")\n",
    ").orderBy(\"prediction\").show()\n",
    "\n",
    "print(\"Распределение локаций по кластерам GMM:\")\n",
    "gmm_results.groupBy(\"prediction\", \"location\").count() \\\n",
    "    .orderBy(\"prediction\", \"count\", ascending=[True, False]) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ca869",
   "metadata": {},
   "source": [
    "#### 3 All Upwork Job Postings - Monthly Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41b0bcab-a135-4733-8557-ff1637cb029d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---------+----------+-----------+------+-------------+\n",
      "|               title|                link|      published_date|is_hourly|hourly_low|hourly_high|budget|      country|\n",
      "+--------------------+--------------------+--------------------+---------+----------+-----------+------+-------------+\n",
      "|Experienced Media...|https://www.upwor...|2024-02-17 09:09:...|    False|      NULL|       NULL| 500.0|         NULL|\n",
      "|Full Stack Developer|https://www.upwor...|2024-02-17 09:09:...|    False|      NULL|       NULL|1100.0|United States|\n",
      "|     SMMA Bubble App|https://www.upwor...|2024-02-17 09:08:...|     True|      10.0|       30.0|  NULL|United States|\n",
      "|Talent Hunter Spe...|https://www.upwor...|2024-02-17 09:08:...|     True|      NULL|       NULL|  NULL|United States|\n",
      "|       Data Engineer|https://www.upwor...|2024-02-17 09:07:...|    False|      NULL|       NULL| 650.0|        India|\n",
      "+--------------------+--------------------+--------------------+---------+----------+-----------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- link: string (nullable = true)\n",
      " |-- published_date: string (nullable = true)\n",
      " |-- is_hourly: string (nullable = true)\n",
      " |-- hourly_low: string (nullable = true)\n",
      " |-- hourly_high: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/opt/data/work\", header=True, inferSchema=True)\n",
    "df.show(5)\n",
    "print(\"Schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4bd7c0-930c-4a34-b19e-02c6d8f35827",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Пропущенные значения:\")\n",
    "for column in df.columns:\n",
    "    null_count = df.filter(col(column).isNull()).count()\n",
    "    print(f\"{column}: {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005936b0-e58a-46f0-858c-639b0a454d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластеризация вакансий по бюджету и типу оплаты:\n",
      "Silhouette Score: 0.9998\n",
      "+----------+------------------+------------------+-------------------+------+\n",
      "|prediction|        avg_budget|   avg_hourly_rate|       hourly_ratio| count|\n",
      "+----------+------------------+------------------+-------------------+------+\n",
      "|         0| 269.7749814074697|3.5802810344097855|0.17042124929711167|826945|\n",
      "|         1| 993903.8072289156|               0.0|                0.0|    83|\n",
      "|         2|410939.28571428574|               0.0|                0.0|   112|\n",
      "+----------+------------------+------------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"budget_clean\", \"hourly_rate\", \"payment_type\"],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "cluster_data = assembler.transform(df_cleaned)\n",
    "\n",
    "kmeans = KMeans(featuresCol=\"features\", k=3, seed=42)\n",
    "kmeans_model = kmeans.fit(cluster_data)\n",
    "kmeans_results = kmeans_model.transform(cluster_data)\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(kmeans_results)\n",
    "\n",
    "print(\"Кластеризация вакансий по бюджету и типу оплаты:\")\n",
    "print(f\"Silhouette Score: {silhouette:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f7876-ed73-444f-b0ab-b289b451f4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классификация типа оплаты по названию:\n",
      "AUC: 0.5784\n",
      "Area Under PR: 0.2186\n",
      "Accuracy: 0.8304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_class = df.withColumn(\"is_hourly_bool\", \n",
    "                        when(col(\"is_hourly\") == \"True\", 1).otherwise(0)) \\\n",
    "             .filter(col(\"title\").isNotNull() & \n",
    "                    col(\"is_hourly_bool\").isNotNull())\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"words\")\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=1000)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"is_hourly_bool\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, hashing_tf, idf, lr])\n",
    "\n",
    "train_data, test_data = df_class.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "model = pipeline.fit(train_data)\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"is_hourly_bool\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator_f1 = BinaryClassificationEvaluator(labelCol=\"is_hourly_bool\", metricName=\"areaUnderPR\")\n",
    "auc_pr = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(\"Классификация типа оплаты по названию:\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Area Under PR: {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3011d4-f215-4030-8bf1-2e80baeb6958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 679:==============>                                         (3 + 9) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказание страны по навыкам:\n",
      "Accuracy: 0.4213\n",
      "F1 Score: 0.2497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "skills_keywords = [\"developer\", \"engineer\", \"designer\", \"writer\", \"marketing\", \n",
    "                   \"data\", \"analysis\", \"python\", \"java\", \"javascript\", \"react\",\n",
    "                   \"sql\", \"aws\", \"azure\", \"web\", \"mobile\", \"app\", \"software\"]\n",
    "\n",
    "df_skills = df.withColumn(\"clean_title\", \n",
    "                         lower(regexp_replace(col(\"title\"), \"[^a-zA-Z\\\\s]\", \"\"))) \\\n",
    "              .filter(col(\"clean_title\").isNotNull())\n",
    "\n",
    "for skill in skills_keywords:\n",
    "    df_skills = df_skills.withColumn(f\"has_{skill}\", \n",
    "                                    when(col(\"clean_title\").contains(skill), 1).otherwise(0))\n",
    "\n",
    "feature_cols = [f\"has_{skill}\" for skill in skills_keywords]\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols, \n",
    "    outputCol=\"skills_features\",\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "df_country = df_skills.filter(col(\"country\").isNotNull() & \n",
    "                             (col(\"country\") != \"NULL\") &\n",
    "                             (col(\"country\") != \"\"))\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"country\", outputCol=\"country_label\")\n",
    "df_indexed = indexer.fit(df_country).transform(df_country)\n",
    "\n",
    "skills_data = assembler.transform(df_indexed)\n",
    "\n",
    "train_data, test_data = skills_data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "nb = NaiveBayes(featuresCol=\"skills_features\", labelCol=\"country_label\", smoothing=1.0)\n",
    "nb_model = nb.fit(train_data)\n",
    "nb_predictions = nb_model.transform(test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"country_label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "f1 = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(\"Предсказание страны по навыкам:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b58d4",
   "metadata": {},
   "source": [
    "#### 4 European Soccer Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f21ceb-4981-4f5e-b521-f51935817b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b65de04",
   "metadata": {},
   "source": [
    "#### 5 Used Cars price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff49a761-4f89-42c8-8188-a0721d532b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----+------+-------+---------+---------+--------------------+---------+------+---------+----------------+\n",
      "|     Make|   Model|Year| Price|Mileage|Body Type|Cylinders|        Transmission|Fuel Type| Color| Location|       Condition|\n",
      "+---------+--------+----+------+-------+---------+---------+--------------------+---------+------+---------+----------------+\n",
      "|      kia| sorento|2013| 61250| 169543|      SUV|        4|Automatic Transmi...| Gasoline|  Grey|Abu Dhabi|Accident history|\n",
      "| cadillac|     srx|2024| 30047|  51876|      SUV|        6|Automatic Transmi...| Gasoline|  Gold|Abu Dhabi| Engine repaired|\n",
      "|    dodge| charger|2022| 31252| 276604|    Sedan|        8|Automatic Transmi...| Gasoline|  Blue|Abu Dhabi| Minor scratches|\n",
      "|  porsche| cayenne|2019| 74335| 278497|      SUV|        6|Automatic Transmi...| Gasoline|Silver|Abu Dhabi|Repainted bumper|\n",
      "|chevrolet|corvette|2018|448226| 140105|    Coupe|        8|Automatic Transmi...| Gasoline|   Red|Abu Dhabi| Engine repaired|\n",
      "+---------+--------+----+------+-------+---------+---------+--------------------+---------+------+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      " |-- Mileage: integer (nullable = true)\n",
      " |-- Body Type: string (nullable = true)\n",
      " |-- Cylinders: string (nullable = true)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Condition: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/opt/data/cars\", header=True, inferSchema=True)\n",
    "df.show(5)\n",
    "print(\"Schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c753cbc-87d6-42d4-97bb-e251e48e6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущенные значения до обработки:\n",
      "Make: 0\n",
      "Model: 0\n",
      "Year: 0\n",
      "Price: 0\n",
      "Mileage: 0\n",
      "Body Type: 0\n",
      "Cylinders: 80\n",
      "Transmission: 0\n",
      "Fuel Type: 0\n",
      "Color: 0\n",
      "Location: 0\n",
      "Condition: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Пропущенные значения до обработки:\")\n",
    "for column in df.columns:\n",
    "    null_count = df.filter(col(column).isNull()).count()\n",
    "    print(f\"{column}: {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da6adbe3-4a3d-4537-a590-9619f6e3ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48323604-ab20-480b-bb05-5aa4fcaf0cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластеризация автомобилей:\n",
      "Silhouette Score: 0.4850\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Price\", \"Mileage\", \"Year\"],\n",
    "    outputCol=\"raw_features\"\n",
    ")\n",
    "df_cluster = assembler.transform(df_cleaned)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"raw_features\", outputCol=\"features\", \n",
    "                       withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(df_cluster)\n",
    "df_scaled = scaler_model.transform(df_cluster)\n",
    "\n",
    "kmeans = KMeans(featuresCol=\"features\", k=4, seed=42)\n",
    "kmeans_model = kmeans.fit(df_scaled)\n",
    "kmeans_results = kmeans_model.transform(df_scaled)\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(kmeans_results)\n",
    "\n",
    "print(\"Кластеризация автомобилей:\")\n",
    "print(f\"Silhouette Score: {silhouette:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f53aab70-a459-4f4d-9c71-62a3c3201ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные после фильтрации типов кузова: 8949 строк\n",
      "Классификация типа кузова:\n",
      "Accuracy: 0.5225\n",
      "F1 Score: 0.4415\n",
      "Распределение предсказаний:\n",
      "+-------------+----------+-----+\n",
      "|    Body Type|prediction|count|\n",
      "+-------------+----------+-----+\n",
      "|        Coupe|       0.0|  229|\n",
      "|        Coupe|       1.0|   16|\n",
      "|    Hatchback|       0.0|   71|\n",
      "|    Hatchback|       1.0|   30|\n",
      "|Pick Up Truck|       0.0|  132|\n",
      "|Pick Up Truck|       1.0|    8|\n",
      "|Pick Up Truck|       3.0|   12|\n",
      "|          SUV|       0.0| 1137|\n",
      "|          SUV|       1.0|  155|\n",
      "|          SUV|       3.0|    2|\n",
      "|        Sedan|       0.0|  595|\n",
      "|        Sedan|       1.0|  208|\n",
      "|        Sedan|       3.0|    2|\n",
      "+-------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body_type_counts = df_cleaned.groupBy(\"Body Type\").count().orderBy(\"count\", ascending=False)\n",
    "main_body_types = [row[\"Body Type\"] for row in body_type_counts.limit(5).collect()]\n",
    "df_filtered_body = df_cleaned.filter(col(\"Body Type\").isin(main_body_types))\n",
    "\n",
    "print(f\"Данные после фильтрации типов кузова: {df_filtered_body.count()} строк\")\n",
    "\n",
    "indexer_body = StringIndexer(inputCol=\"Body Type\", outputCol=\"label\")\n",
    "indexer_fuel = StringIndexer(inputCol=\"Fuel Type\", outputCol=\"fuel_index\")\n",
    "\n",
    "assembler_class = VectorAssembler(\n",
    "    inputCols=[\"Year\", \"Price\", \"Mileage\", \"fuel_index\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", \n",
    "                           numTrees=50, maxBins=100, seed=42)\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer_body, indexer_fuel, assembler_class, rf])\n",
    "\n",
    "train_data, test_data = df_filtered_body.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "model = pipeline.fit(train_data)\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", \n",
    "                                             predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(\"Классификация типа кузова:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Распределение предсказаний:\")\n",
    "predictions.groupBy(\"Body Type\", \"prediction\").count() \\\n",
    "    .orderBy(\"Body Type\", \"prediction\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6ecf029d-3bfd-4fab-86eb-4f2813e42848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/29 21:05:31 WARN Instrumentation: [418ef15a] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ влияния состояния на цену:\n",
      "RMSE: 472678.14\n",
      "R² Score: 0.0004\n",
      "\n",
      "Средняя цена по состояниям:\n",
      "+----------------+------------------+-----+\n",
      "|       Condition|         avg_price|count|\n",
      "+----------------+------------------+-----+\n",
      "|Accident history| 262379.8944815039| 1649|\n",
      "|       No damage| 253654.9388379205| 1635|\n",
      "| Minor scratches|248859.99128811448| 1607|\n",
      "|     Dented door|248809.92188431724| 1677|\n",
      "|Repainted bumper| 233776.2171565687| 1667|\n",
      "| Engine repaired|226921.49554896142| 1685|\n",
      "+----------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer_condition = StringIndexer(inputCol=\"Condition\", outputCol=\"condition_index\")\n",
    "\n",
    "assembler_condition = VectorAssembler(\n",
    "    inputCols=[\"Year\", \"Mileage\", \"condition_index\"],\n",
    "    outputCol=\"features_condition\"\n",
    ")\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features_condition\", labelCol=\"Price\")\n",
    "\n",
    "pipeline_condition = Pipeline(stages=[indexer_condition, assembler_condition, lr])\n",
    "\n",
    "model_condition = pipeline_condition.fit(df_cleaned)\n",
    "predictions_condition = model_condition.transform(df_cleaned)\n",
    "\n",
    "evaluator_condition_rmse = RegressionEvaluator(labelCol=\"Price\", \n",
    "                                              predictionCol=\"prediction\", \n",
    "                                              metricName=\"rmse\")\n",
    "evaluator_condition_r2 = RegressionEvaluator(labelCol=\"Price\", \n",
    "                                            predictionCol=\"prediction\", \n",
    "                                            metricName=\"r2\")\n",
    "\n",
    "rmse_condition = evaluator_condition_rmse.evaluate(predictions_condition)\n",
    "r2_condition = evaluator_condition_r2.evaluate(predictions_condition)\n",
    "\n",
    "print(\"Анализ влияния состояния на цену:\")\n",
    "print(f\"RMSE: {rmse_condition:.2f}\")\n",
    "print(f\"R² Score: {r2_condition:.4f}\")\n",
    "\n",
    "print(\"\\nСредняя цена по состояниям:\")\n",
    "df_cleaned.groupBy(\"Condition\").agg(\n",
    "    mean(\"Price\").alias(\"avg_price\"),\n",
    "    count(\"*\").alias(\"count\")\n",
    ").orderBy(\"avg_price\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726d2a2-abca-4847-9c37-31eec6a4bcab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
